{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.utils import shuffle\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"train.csv\")\n",
    "\n",
    "# Define a mapping dictionary for the classes\n",
    "class_mapping = {\n",
    "    'face_with_mask': 'face_with_mask',\n",
    "    'mask_colorful': 'face_with_mask',\n",
    "    'face_with_mask_incorrect': 'face_with_mask',\n",
    "    'mask_surgical': 'face_with_mask',\n",
    "    'face_other_covering': 'face_with_mask',\n",
    "    'scarf_bandana': 'face_with_mask',\n",
    "    \n",
    "    'face_no_mask': 'face_no_mask',\n",
    "    'eyeglasses': 'face_no_mask',\n",
    "    'helmet': 'face_no_mask',\n",
    "    'face_shield': 'face_no_mask',\n",
    "    'sunglasses': 'face_no_mask',\n",
    "    'hood': 'face_no_mask',\n",
    "    'hat': 'face_no_mask',\n",
    "    'goggles': 'face_no_mask',\n",
    "    'hair_net': 'face_no_mask',\n",
    "    'hijab_niqab': 'face_no_mask',\n",
    "    'other': 'face_no_mask',\n",
    "    'gas_mask': 'face_no_mask',\n",
    "    'balaclava_ski_mask': 'face_no_mask',\n",
    "    'turban': 'face_no_mask'\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the mapping to the 'classname' column\n",
    "df['classname'] = df['classname'].map(class_mapping)\n",
    "\n",
    "# Filter only 'face_with_mask' and 'face_no_mask' classes\n",
    "df = df[df['classname'].isin(['face_with_mask', 'face_no_mask'])]\n",
    "\n",
    "# Preprocess the images and labels\n",
    "images = []\n",
    "labels = []\n",
    "image_size = 128  # Resize images to 128x128\n",
    "\n",
    "# Load and process each image\n",
    "for index, row in df.iterrows():\n",
    "    img_path = os.path.join(\"C:/Users/Hardik Nikam/Downloads/Dataset/Dataset/archive/Medical mask/Medical mask/Medical Mask/images\", row['name'])\n",
    "    img = cv2.imread(img_path)\n",
    "    \n",
    "    if img is not None:\n",
    "        # Resize the image\n",
    "        img = cv2.resize(img, (image_size, image_size))\n",
    "        img = img.astype('float32') / 255.0\n",
    "        images.append(img)\n",
    "        labels.append(row['classname'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hardik Nikam\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m482/482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m150s\u001b[0m 222ms/step - accuracy: 0.6571 - loss: 0.6555\n",
      "Epoch 2/10\n",
      "\u001b[1m482/482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 212ms/step - accuracy: 0.6706 - loss: 0.6373\n",
      "Epoch 3/10\n",
      "\u001b[1m482/482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 211ms/step - accuracy: 0.6655 - loss: 0.6387\n",
      "Epoch 4/10\n",
      "\u001b[1m482/482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 212ms/step - accuracy: 0.6674 - loss: 0.6352\n",
      "Epoch 5/10\n",
      "\u001b[1m482/482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 211ms/step - accuracy: 0.6597 - loss: 0.6305\n",
      "Epoch 6/10\n",
      "\u001b[1m482/482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 212ms/step - accuracy: 0.6699 - loss: 0.6166\n",
      "Epoch 7/10\n",
      "\u001b[1m482/482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 213ms/step - accuracy: 0.6745 - loss: 0.6037\n",
      "Epoch 8/10\n",
      "\u001b[1m482/482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 212ms/step - accuracy: 0.6858 - loss: 0.5880\n",
      "Epoch 9/10\n",
      "\u001b[1m482/482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 211ms/step - accuracy: 0.6937 - loss: 0.5759\n",
      "Epoch 10/10\n",
      "\u001b[1m482/482\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 212ms/step - accuracy: 0.7001 - loss: 0.5646\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1841186e840>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert images and labels to numpy arrays\n",
    "images = np.array(images)\n",
    "labels = np.array(labels)\n",
    "\n",
    "# Encode the labels ('face_with_mask' -> 0, 'face_no_mask' -> 1)\n",
    "le = LabelEncoder()\n",
    "labels = le.fit_transform(labels)\n",
    "labels = to_categorical(labels, 2)  # Convert to one-hot encoding\n",
    "\n",
    "# Shuffle the data\n",
    "images, labels = shuffle(images, labels, random_state=42)\n",
    "\n",
    "# Build the CNN model\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(image_size, image_size, 3)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(2, activation='softmax'))  # Output layer for 2 classes\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(images, labels, epochs=10, batch_size=32)\n",
    "\n",
    "# Save the trained model\n",
    "# model.save(\"face_mask_detection_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "model.save(\"face_mask_detection_model_2.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
